{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "Audio_Authentication_Inference_EN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahathaway821/audio-visual-identity-verification/blob/master/audio_authentication/Audio_Authentication_Inference_EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUl3RAvWpG6Q",
        "colab_type": "code",
        "outputId": "4b94989b-4958-40a2-a2e8-fed9be17644c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "pip install ibm-cos-sdk==2.0.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ibm-cos-sdk==2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/b6/01d723b26bff1c92bbce674531f93d14dbbddbf7570dd58e16dae69589ec/ibm-cos-sdk-2.0.1.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hCollecting ibm-cos-sdk-core==2.*,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/c1/c823507c472bf88dbd045445df6850744111d34fd218c6ea3b9c9bde2cfe/ibm-cos-sdk-core-2.6.0.tar.gz (763kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 13.6MB/s \n",
            "\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.*,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/92/682a28b99777a3fdc65e6d5641ed7e1ca470d0eab3bb2826cc30c6b60e21/ibm-cos-sdk-s3transfer-2.6.0.tar.gz (221kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 68.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (0.15.2)\n",
            "Requirement already satisfied: requests<2.23,>=2.18 in /usr/local/lib/python3.6/dist-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<2.23,>=2.18->ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.23,>=2.18->ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.23,>=2.18->ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<2.23,>=2.18->ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk==2.0.1) (1.12.0)\n",
            "Building wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
            "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.0.1-py2.py3-none-any.whl size=67696 sha256=56dd65b6e93c023137af4dfe0075a41a6eed4a7b5520798fd018547a4b37136e\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/8f/d3/27a98712fa7eaf01c5a76b446ca53f249346dea7c686de0e4e\n",
            "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.6.0-py2.py3-none-any.whl size=446393 sha256=b8aa95ff6d94a7ea32ffd89718bfa6fdd0197af42ac8e13713e308305b2fe3c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/93/e6/23071b2c037147a0993d34b64a03e51abca84435fc9cd6a278\n",
            "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.6.0-py2.py3-none-any.whl size=89244 sha256=dea3559b5526a5b8d418fbab242047a6226cabe7d9104c0197ae43bb07677105\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/d9/d7/43fd95b014eed89466154d8373bf4cffbb3d972de7841e213c\n",
            "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
            "Installing collected packages: ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk\n",
            "Successfully installed ibm-cos-sdk-2.0.1 ibm-cos-sdk-core-2.6.0 ibm-cos-sdk-s3transfer-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieL4ubmSrLg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import ibm_boto3\n",
        "from ibm_botocore.client import Config, ClientError\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input, optimizers, metrics, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Constants for IBM S3 values\n",
        "COS_ENDPOINT = 'https://s3.us-south.cloud-object-storage.appdomain.cloud'\n",
        "COS_API_KEY_ID = 'LKRr_5OhOyBgvHG6WH2wm9F_2bHC2sn1vV4eaCYdgpsm'\n",
        "COS_AUTH_ENDPOINT = 'https://iam.cloud.ibm.com/identity/token'\n",
        "COS_RESOURCE_CRN = 'crn:v1:bluemix:public:cloud-object-storage:global:a/ea337a3eba2f43c6b813f319db505255:0f9730a8-f2b8-42ce-b276-f9e13877a5f0::'\n",
        "\n",
        "DATA_PATH = 'data/'\n",
        "BUCKET_NAME = 'cv-audio'\n",
        "DEV_FILE = 'dev.tsv'\n",
        "AUDIO_FILE = 'dev-clips.tgz'\n",
        "MFCC_PICKLE = 'mfcc.bin'\n",
        "CLIPS_PATH = DATA_PATH + 'dev-clips/'\n",
        "TEST_CLIPS = DATA_PATH + 'test-clips/'\n",
        "BEST_MODEL_FILE = 'model-EN-20200329-133052.tgz'\n",
        "TEST_RECORDINGS = 'test-clips.tgz'\n",
        "\n",
        "PROD_PATH = DATA_PATH + 'production/'\n",
        "REF_CLIP = PROD_PATH + 'ref_clip.wav'\n",
        "REF_CLIPS_PICKLE = PROD_PATH + 'ref_clips.pickle'\n",
        "BEST_MODEL_PATH = DATA_PATH + 'production/model/'\n",
        "SCORE_THRESHOLD = 0.5\n",
        "REF_CLIPS = None\n",
        "MODEL = None\n",
        "\n",
        "bucket_name = 'cv-audio'\n",
        "\n",
        "cos = ibm_boto3.resource(\"s3\",\n",
        "    ibm_api_key_id=COS_API_KEY_ID,\n",
        "    ibm_service_instance_id=COS_RESOURCE_CRN,\n",
        "    ibm_auth_endpoint=COS_AUTH_ENDPOINT,\n",
        "    config=Config(signature_version=\"oauth\"),\n",
        "    endpoint_url=COS_ENDPOINT\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8gQbBX7CqpG",
        "colab_type": "text"
      },
      "source": [
        "### Pull Down Necessary Files from Bucket for Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL14ecE4tmUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MFCC Clips\n",
        "if not os.path.exists(PROD_PATH):\n",
        "    os.makedirs(PROD_PATH)\n",
        "    \n",
        "mfccPickleResponse = cos.Object(bucket_name, MFCC_PICKLE).get()\n",
        "mfccPickle = mfccPickleResponse['Body'].read()\n",
        "with open(REF_CLIPS_PICKLE, 'wb') as f:\n",
        "    pickle.dump(mfccPickle, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ85181B1gWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model\n",
        "modelResponse = cos.Object(bucket_name, BEST_MODEL_FILE).get()\n",
        "model_tar = modelResponse['Body'].read()\n",
        "if not os.path.exists(BEST_MODEL_PATH):\n",
        "    os.makedirs(BEST_MODEL_PATH)\n",
        "with open(BEST_MODEL_PATH + BEST_MODEL_FILE , 'wb') as file:\n",
        "    file.write(model_tar)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7gBI3Iz5vH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0727c805-d203-4036-cce2-f93281f183c6"
      },
      "source": [
        "!tar zxvf /content/data/production/model/model-EN-20200329-133052.tgz -C /content/data/production/model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EN-20200329-133052/\n",
            "EN-20200329-133052/variables/\n",
            "EN-20200329-133052/variables/variables.index\n",
            "EN-20200329-133052/variables/variables.data-00000-of-00002\n",
            "EN-20200329-133052/variables/variables.data-00001-of-00002\n",
            "EN-20200329-133052/assets/\n",
            "EN-20200329-133052/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrTz_tICCuxd",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sno1G06nor_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips(clip_path, recorded_byte_array, min_size=1):    \n",
        "    \"\"\"\n",
        "    Splits a long clip in multiple smaller clips with MFCC length of 400. \n",
        "    Also discards the final part of the audio file the is not a multiple of 400.\n",
        "    \"\"\"\n",
        "    \n",
        "    #TODO: this function should also work with a recorded byte array\n",
        "    # since we don't need to save the user's voice everytime they try to open the door\n",
        "    \n",
        "    pad_length = 400\n",
        "    \n",
        "    wave, sr = librosa.load(clip_path, mono=True)\n",
        "    wave = wave[::3]\n",
        "    mfcc = librosa.feature.mfcc(wave, sr=sr)\n",
        "        \n",
        "    n_clips = int(mfcc.shape[1] / pad_length)\n",
        "    \n",
        "    if (n_clips < min_size):\n",
        "        raise Exception('Audio file too short. Expected MFCC equal or greater than {}, but was: {}'.format(\n",
        "            min_size*400, mfcc.shape[1]))\n",
        "    \n",
        "    # cut the recording in smaller clips\n",
        "    ref_clips = []\n",
        "    for i in range(1, n_clips+1):\n",
        "        ref_clips.append(mfcc[:, (i-1)*pad_length:i*pad_length])\n",
        "        \n",
        "    # REMOVED: a tiny part could lead to a bad score\n",
        "    # add the last clip and fill with zeros up to 400\n",
        "    #last = mfcc[:, n_clips*pad_length:mfcc.shape[1]]\n",
        "    #if(last.shape[1] > 0): \n",
        "    #    ref_clips.append(np.pad(\n",
        "    #        last, \n",
        "    #        pad_width = ((0, 0), (0, pad_length - last.shape[1])),\n",
        "    #        mode = 'constant'))\n",
        "    \n",
        "    return ref_clips\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbS8-fELor_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_voice_system():   \n",
        "    \"\"\"\n",
        "    Records the voice of the user, splits the voice in small clippings and saves\n",
        "    the clippings for later inference.\n",
        "    \"\"\"\n",
        "    \n",
        "    #TODO\n",
        "    #record the voice and save the file in path REF_CLIP\n",
        "    #if time allows, multiple users to open the door\n",
        "    \n",
        "    # expect at least 3 clips from reference recording \n",
        "    ref_clips = get_clips(REF_CLIP, 3)\n",
        "    \n",
        "    with open(REF_CLIPS_PICKLE, 'wb') as handle: \n",
        "        pickle.dump(ref_clips, handle)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYzv9HlLor_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f95a352-f65d-4514-808e-8520c29c2caf"
      },
      "source": [
        "def start_voice_system():\n",
        "    \"\"\"\n",
        "    Loads the reference clippings and the weights of the model.\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        with open(REF_CLIPS_PICKLE, 'rb') as handle:\n",
        "            REF_CLIPS = pickle.load(handle) \n",
        "    except Exception as e:\n",
        "        raise Exception('Could not find reference voice clips. Was the system set up?')\n",
        "\n",
        "        \n",
        "    MODEL = models.load_model(BEST_MODEL_PATH + \"EN-20200329-133052\")    \n",
        "        \n",
        "    return ref_clips, model\n",
        "BEST_MODEL_PATH + \"EN-20200329-133052\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/production/model/EN-20200329-133052'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjMs7xwtor_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_user_voice():\n",
        "    \"\"\"\n",
        "    Record the user voice for an attempted unlock and return smaller processed MFCC clippings\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    recorded_byte_array = np.array()\n",
        "    \n",
        "    return get_clips(None, recorded_byte_array, min_size=1):   \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezoPzF52osAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_inference_dataset(actual_clips):\n",
        "    left = []\n",
        "    right = []\n",
        "    \n",
        "    for ref in REF_CLIPS:\n",
        "        for actual in actual_clips:\n",
        "            left.append([ref]) \n",
        "            right.append([actual]) \n",
        "    \n",
        "    left = np.array(left).astype(np.float32)\n",
        "    right = np.array(right).astype(np.float32)\n",
        "\n",
        "    left = np.rollaxis(np.rollaxis(left, 3, 1), 3, 1)\n",
        "    right = np.rollaxis(np.rollaxis(right, 3, 1), 3, 1)\n",
        "\n",
        "    return left, right"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-3ow7-IosAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def speech_unlock(left, right):\n",
        "    return np.mean(MODEL.predict([left, right])) > SCORE_THRESHOLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf3pXLCKosAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a072355-d517-413c-d546-3f2a6cb1969d"
      },
      "source": [
        "# main.py in TX2 should contain something like this\n",
        "\n",
        "#setup_voice_system()\n",
        "\n",
        "#current error from running model on 3.5 then loading on 3.6?\n",
        "ref_clips, model = start_voice_system()\n",
        "\n",
        "#actual_clips = get_user_voice()\n",
        "\n",
        "#left, right = get_inference_dataset(ref_clips, actual_clips)\n",
        "\n",
        "#unlock = speech_unlock(left, right)\n",
        "\n",
        "#if (unlock):\n",
        "    #do something"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1b63d1992567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mref_clips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_voice_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#actual_clips = get_user_voice()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-3ff245ddbf83>\u001b[0m in \u001b[0;36mstart_voice_system\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBEST_MODEL_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"EN-20200329-133052\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mref_clips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   raise IOError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;31m# TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;31m# TODO(kathywu): Add code to load from objects that contain all endpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    602\u001b[0m       loader = loader_cls(object_graph_proto,\n\u001b[1;32m    603\u001b[0m                           \u001b[0msaved_model_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                           export_dir)\n\u001b[0m\u001b[1;32m    605\u001b[0m       \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models_to_reconstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# Now that the node object has been fully loaded, and the checkpoint has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir)\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WrapperFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_load_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m# Finish setting up layers and models. See function docstring for more info.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_finalize_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;31m# Initialize graph networks, now that layer dependencies have been resolved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reconstruct_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_unblock_model_reconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_reconstruct_all_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m       \u001b[0mall_initialized_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_layer_dependencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reconstruct_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_object_graph_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m       \u001b[0m_finalize_config_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_reconstruct_model\u001b[0;34m(self, model_id, model, layers)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       (inputs, outputs, created_layers) = network_lib.reconstruct_from_config(\n\u001b[0;32m--> 564\u001b[0;31m           config, created_layers={layer.name: layer for layer in layers})\n\u001b[0m\u001b[1;32m    565\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0mnetwork_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_ancillary_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   2022\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m           \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m   \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1970\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnest_if_single_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1972\u001b[0;31m       \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m       \u001b[0;31m# Update node index map.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    920\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwatch_accessed_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(tensors)\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: unknown opcode"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJNwfG9-osAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}