{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SebxTmpBlunC"
   },
   "source": [
    "### Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "osx9AxwglunD",
    "outputId": "60f02d14-0a3e-4765-c2ef-d55385f96d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.5.3 (default, Sep 27 2018, 17:25:39) \n",
      "[GCC 6.3.0 20170516]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=5, micro=3, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3zEjn_SxlunH",
    "outputId": "a77b9422-af1d-4f40-ef7a-ac70f425cb49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime as datetime\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, precision_recall_curve, precision_score, average_precision_score\n",
    "\n",
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config, ClientError\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Input, optimizers, metrics, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "SEED = 101\n",
    "random.seed(SEED)\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uYe847ulunK"
   },
   "source": [
    "### Loading files from bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPf66yBilunK"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/csanc/'\n",
    "BUCKET_NAME = 'cv-audio'\n",
    "\n",
    "DATASET_PICKLE = 'mfcc/dataset.npz'\n",
    "\n",
    "TEST_CLIPS = DATA_PATH + 'test-clips/'\n",
    "BEST_MODEL_FILE = 'EN-TF1-Full-20200408-194433'\n",
    "\n",
    "DATASET_SPLITS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "jSA-fRLBmrJs",
    "outputId": "3748c0a8-1286-491c-8ccf-36d9b4dcccf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cuda-repo-ubuntu1604-10-1-local-10.1.168-418.67_1.0-1_amd64.deb',\n",
       " 'OneShot_Speech_Carlos_EN-TF1-Full.ipynb',\n",
       " 'nohup.out',\n",
       " '.gnupg',\n",
       " 'dataset.npz',\n",
       " '.viminfo',\n",
       " 'cuda-repo-ubuntu1604-10-1-local-10.1.105-418.39_1.0-1_amd64.deb',\n",
       " '.profile',\n",
       " '.bash_history',\n",
       " '.bashrc',\n",
       " '.ssh',\n",
       " '.ipynb_checkpoints',\n",
       " '.cache']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2w5GwCalunN"
   },
   "outputs": [],
   "source": [
    "# Constants for IBM S3 values\n",
    "COS_ENDPOINT = 'https://s3.us-south.cloud-object-storage.appdomain.cloud'\n",
    "COS_API_KEY_ID = 'LKRr_5OhOyBgvHG6WH2wm9F_2bHC2sn1vV4eaCYdgpsm'\n",
    "COS_AUTH_ENDPOINT = 'https://iam.cloud.ibm.com/identity/token'\n",
    "COS_RESOURCE_CRN = 'crn:v1:bluemix:public:cloud-object-storage:global:a/ea337a3eba2f43c6b813f319db505255:0f9730a8-f2b8-42ce-b276-f9e13877a5f0::'\n",
    "\n",
    "# Create resource\n",
    "cos = ibm_boto3.resource(\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_RESOURCE_CRN,\n",
    "    ibm_auth_endpoint=COS_AUTH_ENDPOINT,\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = cos.Bucket(BUCKET_NAME)\n",
    "obj = bucket.Object(DATASET_PICKLE)\n",
    "\n",
    "with open(DATA_PATH + DATASET_PICKLE, 'wb') as data:\n",
    "    obj.download_fileobj(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0_nBVWKlunV"
   },
   "source": [
    "### Save files to the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyziWqUolunW"
   },
   "outputs": [],
   "source": [
    "# Create resource\n",
    "cos = ibm_boto3.client(\n",
    "    service_name=\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_RESOURCE_CRN,\n",
    "    ibm_auth_endpoint=COS_AUTH_ENDPOINT,\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'checkpoints/model_en_full.tgz', 'rb') as data:\n",
    "    cos.upload_fileobj(data, BUCKET_NAME, 'model_en_full.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vf-z0VkllunZ",
    "outputId": "934740f4-a952-4234-ab7c-b287eef9547a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: EN-TF1-20200405-024254.tgz (50895219 bytes).\n",
      "Item: dataset.npz (8414671607 bytes).\n",
      "Item: dev-clips-wav.tgz (372144992 bytes).\n",
      "Item: dev-clips.tgz (729032372 bytes).\n",
      "Item: dev.tsv (3555470 bytes).\n",
      "Item: en-clips.tgz (41357019402 bytes).\n",
      "Item: mfcc.bin (499906808 bytes).\n",
      "Item: model-EN-20200329-133052.tgz (152577527 bytes).\n",
      "Item: model_en_full.tgz (129735130 bytes).\n",
      "Item: test-clips.tgz (992056 bytes).\n",
      "Item: test.tsv (3401154 bytes).\n",
      "Item: test.txt (4 bytes).\n",
      "Item: train.tsv (55941783 bytes).\n"
     ]
    }
   ],
   "source": [
    "cos = ibm_boto3.resource(\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_RESOURCE_CRN,\n",
    "    ibm_auth_endpoint=COS_AUTH_ENDPOINT,\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")\n",
    "\n",
    "for file in cos.Bucket(BUCKET_NAME).objects.all():\n",
    "    print(\"Item: {0} ({1} bytes).\".format(file.key, file.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MP3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip(file_name, max_pad_len=400):\n",
    "    wave, sr = librosa.load(file_name, mono=True)\n",
    "    wave = wave[::3]\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=sr) \n",
    "\n",
    "    pad_width = max_pad_len - mfcc.shape[1]\n",
    "    \n",
    "    if (pad_width < 0): \n",
    "        pad_width = 0\n",
    "        mfcc = mfcc[:, 0:max_pad_len]\n",
    "    \n",
    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfcc.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM8xe3grluqS"
   },
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/csanc/mfcc/dataset.npz'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH + DATASET_PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(DATA_PATH + DATASET_PICKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((671745, 20, 400, 1), (671745, 20, 400, 1), (671745,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = dataset['left']\n",
    "right = dataset['right']\n",
    "labels = dataset['labels']\n",
    "left.shape, right.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671745, 470221)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = left.shape[0]\n",
    "train_size = int(dataset_size*0.7)\n",
    "dataset_size, train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5PCpQZ4luqU"
   },
   "outputs": [],
   "source": [
    "def get_siamese_model():\n",
    "  \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input((20, 400, 1))\n",
    "    right_input = Input((20, 400, 1))\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = models.Sequential()    \n",
    "    model.add(layers.Conv2D(\n",
    "        32, \n",
    "        (10,10), \n",
    "        padding = 'same',\n",
    "        activation='relu', \n",
    "        input_shape=(20, 400, 1), \n",
    "        kernel_regularizer=regularizers.l2(2e-4)))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(\n",
    "        64, \n",
    "        (7,7),  \n",
    "        padding = 'same',\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(2e-4)))    \n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(\n",
    "        64, \n",
    "        (4,4), \n",
    "        padding = 'same', \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(2e-4)))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(\n",
    "        128, \n",
    "        (4,4),  \n",
    "        padding = 'same',\n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(2e-4)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(\n",
    "        1024, \n",
    "        activation='sigmoid',\n",
    "        kernel_regularizer=regularizers.l2(1e-3)))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = layers.Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = layers.Dense(1, activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = models.Model(inputs=[left_input, right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDKwqmGaluqZ"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "colab_type": "code",
    "id": "c4gHhZOoluqZ",
    "outputId": "0eab4686-c517-4f10-81cf-4dbfa4f6cf58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20, 400, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 20, 400, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 1024)         13408672    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1024)         0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 13,409,697\n",
      "Trainable params: 13,409,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "cYAkHySyluqc",
    "outputId": "52d50670-b628-4751-ee22-1fce72ae7717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-4\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer = optimizers.Adam(lr = LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQUO5DcVluqf"
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#log_dir = DATA_PATH + 'logs/EN-TF1-' + now\n",
    "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_path = DATA_PATH + 'checkpoints/EN-TF1-Full-' + now\n",
    "checkpoints_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only = True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4CLjoBCtluqi",
    "outputId": "de6a2423-296c-4362-d692-cff2491e23ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_path)\n",
    "#print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3fe8RNLlup8"
   },
   "outputs": [],
   "source": [
    "#left_train, left_val, right_train, right_val, labels_train, labels_val\n",
    "#left[0:train_size]\n",
    "#left[train_size:dataset_size]\n",
    "\n",
    "#right[0:train_size]\n",
    "#right[train_size:dataset_size]\n",
    "\n",
    "#labels[0:train_size]\n",
    "#labels[train_size:dataset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "4zYFUUAaluql",
    "outputId": "5a0f5fd4-0e1d-49dc-9bdb-7456fac15037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470221 samples, validate on 201524 samples\n",
      "Epoch 1/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.4887\n",
      "Epoch 00001: val_loss improved from inf to 0.23372, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 301s 641us/sample - loss: 0.4885 - val_loss: 0.2337\n",
      "Epoch 2/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.1908\n",
      "Epoch 00002: val_loss improved from 0.23372 to 0.16572, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 185s 394us/sample - loss: 0.1907 - val_loss: 0.1657\n",
      "Epoch 3/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.1445\n",
      "Epoch 00003: val_loss improved from 0.16572 to 0.13763, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 178s 378us/sample - loss: 0.1445 - val_loss: 0.1376\n",
      "Epoch 4/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.1226\n",
      "Epoch 00004: val_loss improved from 0.13763 to 0.12864, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 177s 376us/sample - loss: 0.1226 - val_loss: 0.1286\n",
      "Epoch 5/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.1091\n",
      "Epoch 00005: val_loss improved from 0.12864 to 0.12180, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.1091 - val_loss: 0.1218\n",
      "Epoch 6/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0986\n",
      "Epoch 00006: val_loss improved from 0.12180 to 0.11454, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0986 - val_loss: 0.1145\n",
      "Epoch 7/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0898\n",
      "Epoch 00007: val_loss improved from 0.11454 to 0.11258, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0898 - val_loss: 0.1126\n",
      "Epoch 8/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0829\n",
      "Epoch 00008: val_loss improved from 0.11258 to 0.11059, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 176s 373us/sample - loss: 0.0829 - val_loss: 0.1106\n",
      "Epoch 9/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0774\n",
      "Epoch 00009: val_loss improved from 0.11059 to 0.10229, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0774 - val_loss: 0.1023\n",
      "Epoch 10/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0726\n",
      "Epoch 00010: val_loss improved from 0.10229 to 0.10140, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0726 - val_loss: 0.1014\n",
      "Epoch 11/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0692\n",
      "Epoch 00011: val_loss improved from 0.10140 to 0.09985, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0692 - val_loss: 0.0999\n",
      "Epoch 12/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0666\n",
      "Epoch 00012: val_loss improved from 0.09985 to 0.09952, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0666 - val_loss: 0.0995\n",
      "Epoch 13/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0637\n",
      "Epoch 00013: val_loss improved from 0.09952 to 0.09941, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0637 - val_loss: 0.0994\n",
      "Epoch 14/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0621\n",
      "Epoch 00014: val_loss improved from 0.09941 to 0.09886, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 183s 388us/sample - loss: 0.0621 - val_loss: 0.0989\n",
      "Epoch 15/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0608\n",
      "Epoch 00015: val_loss improved from 0.09886 to 0.09419, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0608 - val_loss: 0.0942\n",
      "Epoch 16/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0582\n",
      "Epoch 00016: val_loss improved from 0.09419 to 0.09278, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 173s 367us/sample - loss: 0.0582 - val_loss: 0.0928\n",
      "Epoch 17/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0570\n",
      "Epoch 00017: val_loss did not improve from 0.09278\n",
      "470221/470221 [==============================] - 172s 365us/sample - loss: 0.0570 - val_loss: 0.0941\n",
      "Epoch 18/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0567\n",
      "Epoch 00018: val_loss improved from 0.09278 to 0.09271, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0567 - val_loss: 0.0927\n",
      "Epoch 19/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0547\n",
      "Epoch 00019: val_loss improved from 0.09271 to 0.08914, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0547 - val_loss: 0.0891\n",
      "Epoch 20/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0539\n",
      "Epoch 00020: val_loss did not improve from 0.08914\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0539 - val_loss: 0.0917\n",
      "Epoch 21/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0539\n",
      "Epoch 00021: val_loss did not improve from 0.08914\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0539 - val_loss: 0.0921\n",
      "Epoch 22/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0521\n",
      "Epoch 00022: val_loss did not improve from 0.08914\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0521 - val_loss: 0.0906\n",
      "Epoch 23/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0499\n",
      "Epoch 00023: val_loss did not improve from 0.08914\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0499 - val_loss: 0.0912\n",
      "Epoch 24/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0523\n",
      "Epoch 00024: val_loss did not improve from 0.08914\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0523 - val_loss: 0.0892\n",
      "Epoch 25/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0497\n",
      "Epoch 00025: val_loss improved from 0.08914 to 0.08608, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0497 - val_loss: 0.0861\n",
      "Epoch 26/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0488\n",
      "Epoch 00026: val_loss improved from 0.08608 to 0.08403, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0488 - val_loss: 0.0840\n",
      "Epoch 27/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0493\n",
      "Epoch 00027: val_loss did not improve from 0.08403\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0494 - val_loss: 0.0863\n",
      "Epoch 28/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0482\n",
      "Epoch 00028: val_loss did not improve from 0.08403\n",
      "470221/470221 [==============================] - 172s 366us/sample - loss: 0.0482 - val_loss: 0.0880\n",
      "Epoch 29/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0476\n",
      "Epoch 00029: val_loss did not improve from 0.08403\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0476 - val_loss: 0.0859\n",
      "Epoch 30/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0474\n",
      "Epoch 00030: val_loss improved from 0.08403 to 0.08380, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 177s 375us/sample - loss: 0.0474 - val_loss: 0.0838\n",
      "Epoch 31/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0462\n",
      "Epoch 00031: val_loss did not improve from 0.08380\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0462 - val_loss: 0.0838\n",
      "Epoch 32/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0466\n",
      "Epoch 00032: val_loss improved from 0.08380 to 0.08128, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0466 - val_loss: 0.0813\n",
      "Epoch 33/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0439\n",
      "Epoch 00033: val_loss did not improve from 0.08128\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0439 - val_loss: 0.0841\n",
      "Epoch 34/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0456\n",
      "Epoch 00034: val_loss did not improve from 0.08128\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0456 - val_loss: 0.0835\n",
      "Epoch 35/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0446\n",
      "Epoch 00035: val_loss improved from 0.08128 to 0.07860, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 371us/sample - loss: 0.0446 - val_loss: 0.0786\n",
      "Epoch 36/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0442\n",
      "Epoch 00036: val_loss did not improve from 0.07860\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0442 - val_loss: 0.0828\n",
      "Epoch 37/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0441\n",
      "Epoch 00037: val_loss did not improve from 0.07860\n",
      "470221/470221 [==============================] - 172s 367us/sample - loss: 0.0441 - val_loss: 0.0811\n",
      "Epoch 38/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0442\n",
      "Epoch 00038: val_loss did not improve from 0.07860\n",
      "470221/470221 [==============================] - 172s 367us/sample - loss: 0.0442 - val_loss: 0.0817\n",
      "Epoch 39/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0436\n",
      "Epoch 00039: val_loss did not improve from 0.07860\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0436 - val_loss: 0.0809\n",
      "Epoch 40/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0424\n",
      "Epoch 00040: val_loss did not improve from 0.07860\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0424 - val_loss: 0.0796\n",
      "Epoch 41/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0432\n",
      "Epoch 00041: val_loss did not improve from 0.07860\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0432 - val_loss: 0.0808\n",
      "Epoch 42/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0410\n",
      "Epoch 00042: val_loss did not improve from 0.07860\n",
      "470221/470221 [==============================] - 175s 371us/sample - loss: 0.0410 - val_loss: 0.0811\n",
      "Epoch 43/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0430\n",
      "Epoch 00043: val_loss did not improve from 0.07860\n",
      "470221/470221 [==============================] - 175s 371us/sample - loss: 0.0430 - val_loss: 0.0815\n",
      "Epoch 44/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0393\n",
      "Epoch 00044: val_loss improved from 0.07860 to 0.07841, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0393 - val_loss: 0.0784\n",
      "Epoch 45/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0417\n",
      "Epoch 00045: val_loss did not improve from 0.07841\n",
      "470221/470221 [==============================] - 172s 367us/sample - loss: 0.0417 - val_loss: 0.0809\n",
      "Epoch 46/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0419\n",
      "Epoch 00046: val_loss improved from 0.07841 to 0.07748, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0419 - val_loss: 0.0775\n",
      "Epoch 47/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0400\n",
      "Epoch 00047: val_loss did not improve from 0.07748\n",
      "470221/470221 [==============================] - 173s 367us/sample - loss: 0.0400 - val_loss: 0.0782\n",
      "Epoch 48/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0401\n",
      "Epoch 00048: val_loss did not improve from 0.07748\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0401 - val_loss: 0.0785\n",
      "Epoch 49/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0407\n",
      "Epoch 00049: val_loss improved from 0.07748 to 0.07740, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 177s 375us/sample - loss: 0.0407 - val_loss: 0.0774\n",
      "Epoch 50/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0395\n",
      "Epoch 00050: val_loss did not improve from 0.07740\n",
      "470221/470221 [==============================] - 174s 371us/sample - loss: 0.0395 - val_loss: 0.0795\n",
      "Epoch 51/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0386\n",
      "Epoch 00051: val_loss did not improve from 0.07740\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0386 - val_loss: 0.0784\n",
      "Epoch 52/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0408\n",
      "Epoch 00052: val_loss improved from 0.07740 to 0.07736, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0408 - val_loss: 0.0774\n",
      "Epoch 53/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0385\n",
      "Epoch 00053: val_loss did not improve from 0.07736\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0385 - val_loss: 0.0792\n",
      "Epoch 54/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0389\n",
      "Epoch 00054: val_loss did not improve from 0.07736\n",
      "470221/470221 [==============================] - 172s 366us/sample - loss: 0.0389 - val_loss: 0.0792\n",
      "Epoch 55/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0399\n",
      "Epoch 00055: val_loss did not improve from 0.07736\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0399 - val_loss: 0.0799\n",
      "Epoch 56/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0385\n",
      "Epoch 00056: val_loss improved from 0.07736 to 0.07525, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0385 - val_loss: 0.0753\n",
      "Epoch 57/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0370\n",
      "Epoch 00057: val_loss did not improve from 0.07525\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0370 - val_loss: 0.0775\n",
      "Epoch 58/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0381\n",
      "Epoch 00058: val_loss did not improve from 0.07525\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0381 - val_loss: 0.0806\n",
      "Epoch 59/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0388\n",
      "Epoch 00059: val_loss did not improve from 0.07525\n",
      "470221/470221 [==============================] - 172s 366us/sample - loss: 0.0388 - val_loss: 0.0776\n",
      "Epoch 60/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0364\n",
      "Epoch 00060: val_loss improved from 0.07525 to 0.07503, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0364 - val_loss: 0.0750\n",
      "Epoch 61/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0373\n",
      "Epoch 00061: val_loss did not improve from 0.07503\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0373 - val_loss: 0.0761\n",
      "Epoch 62/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0388\n",
      "Epoch 00062: val_loss improved from 0.07503 to 0.07396, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0388 - val_loss: 0.0740\n",
      "Epoch 63/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0360\n",
      "Epoch 00063: val_loss improved from 0.07396 to 0.07390, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0360 - val_loss: 0.0739\n",
      "Epoch 64/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0362\n",
      "Epoch 00064: val_loss did not improve from 0.07390\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0363 - val_loss: 0.0817\n",
      "Epoch 65/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0373\n",
      "Epoch 00065: val_loss improved from 0.07390 to 0.07381, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0373 - val_loss: 0.0738\n",
      "Epoch 66/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0357\n",
      "Epoch 00066: val_loss did not improve from 0.07381\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0357 - val_loss: 0.0763\n",
      "Epoch 67/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0374\n",
      "Epoch 00067: val_loss did not improve from 0.07381\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0374 - val_loss: 0.0773\n",
      "Epoch 68/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0349\n",
      "Epoch 00068: val_loss did not improve from 0.07381\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0349 - val_loss: 0.0766\n",
      "Epoch 69/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0381\n",
      "Epoch 00069: val_loss did not improve from 0.07381\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0381 - val_loss: 0.0740\n",
      "Epoch 70/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0348\n",
      "Epoch 00070: val_loss improved from 0.07381 to 0.07078, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 371us/sample - loss: 0.0348 - val_loss: 0.0708\n",
      "Epoch 71/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0355\n",
      "Epoch 00071: val_loss did not improve from 0.07078\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0355 - val_loss: 0.0783\n",
      "Epoch 72/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0372\n",
      "Epoch 00072: val_loss did not improve from 0.07078\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0372 - val_loss: 0.0717\n",
      "Epoch 73/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0348\n",
      "Epoch 00073: val_loss did not improve from 0.07078\n",
      "470221/470221 [==============================] - 171s 365us/sample - loss: 0.0348 - val_loss: 0.0723\n",
      "Epoch 74/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0363\n",
      "Epoch 00074: val_loss did not improve from 0.07078\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0363 - val_loss: 0.0752\n",
      "Epoch 75/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0359\n",
      "Epoch 00075: val_loss did not improve from 0.07078\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0359 - val_loss: 0.0729\n",
      "Epoch 76/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0339\n",
      "Epoch 00076: val_loss did not improve from 0.07078\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0339 - val_loss: 0.0715\n",
      "Epoch 77/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0357\n",
      "Epoch 00077: val_loss did not improve from 0.07078\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0357 - val_loss: 0.0765\n",
      "Epoch 78/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0351\n",
      "Epoch 00078: val_loss did not improve from 0.07078\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0351 - val_loss: 0.0723\n",
      "Epoch 79/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0326\n",
      "Epoch 00079: val_loss improved from 0.07078 to 0.06855, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0326 - val_loss: 0.0685\n",
      "Epoch 80/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0361\n",
      "Epoch 00080: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0361 - val_loss: 0.0721\n",
      "Epoch 81/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0345\n",
      "Epoch 00081: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0345 - val_loss: 0.0729\n",
      "Epoch 82/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0338\n",
      "Epoch 00082: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0338 - val_loss: 0.0742\n",
      "Epoch 83/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0360\n",
      "Epoch 00083: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0360 - val_loss: 0.0701\n",
      "Epoch 84/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0318\n",
      "Epoch 00084: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0318 - val_loss: 0.0726\n",
      "Epoch 85/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0340\n",
      "Epoch 00085: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 173s 367us/sample - loss: 0.0340 - val_loss: 0.0730\n",
      "Epoch 86/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0333\n",
      "Epoch 00086: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0333 - val_loss: 0.0702\n",
      "Epoch 87/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0339\n",
      "Epoch 00087: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0339 - val_loss: 0.0735\n",
      "Epoch 88/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0328\n",
      "Epoch 00088: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0328 - val_loss: 0.0686\n",
      "Epoch 89/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0321\n",
      "Epoch 00089: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0321 - val_loss: 0.0747\n",
      "Epoch 90/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0347\n",
      "Epoch 00090: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0347 - val_loss: 0.0736\n",
      "Epoch 91/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0329\n",
      "Epoch 00091: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0329 - val_loss: 0.0707\n",
      "Epoch 92/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0327\n",
      "Epoch 00092: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0327 - val_loss: 0.0726\n",
      "Epoch 93/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0330\n",
      "Epoch 00093: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0331 - val_loss: 0.0739\n",
      "Epoch 94/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0326\n",
      "Epoch 00094: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0326 - val_loss: 0.0697\n",
      "Epoch 95/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0308\n",
      "Epoch 00095: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0308 - val_loss: 0.0717\n",
      "Epoch 96/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0337\n",
      "Epoch 00096: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0337 - val_loss: 0.0737\n",
      "Epoch 97/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0314\n",
      "Epoch 00097: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0314 - val_loss: 0.0689\n",
      "Epoch 98/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0325\n",
      "Epoch 00098: val_loss did not improve from 0.06855\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0325 - val_loss: 0.0723\n",
      "Epoch 99/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0316\n",
      "Epoch 00099: val_loss improved from 0.06855 to 0.06809, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 177s 377us/sample - loss: 0.0316 - val_loss: 0.0681\n",
      "Epoch 100/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0317\n",
      "Epoch 00100: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0317 - val_loss: 0.0762\n",
      "Epoch 101/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0328\n",
      "Epoch 00101: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0328 - val_loss: 0.0707\n",
      "Epoch 102/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0310\n",
      "Epoch 00102: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0310 - val_loss: 0.0710\n",
      "Epoch 103/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0310\n",
      "Epoch 00103: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0310 - val_loss: 0.0704\n",
      "Epoch 104/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0322\n",
      "Epoch 00104: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0322 - val_loss: 0.0692\n",
      "Epoch 105/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0298\n",
      "Epoch 00105: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0298 - val_loss: 0.0706\n",
      "Epoch 106/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0324\n",
      "Epoch 00106: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 174s 371us/sample - loss: 0.0324 - val_loss: 0.0693\n",
      "Epoch 107/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0312\n",
      "Epoch 00107: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0312 - val_loss: 0.0702\n",
      "Epoch 108/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0302\n",
      "Epoch 00108: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0302 - val_loss: 0.0714\n",
      "Epoch 109/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0313\n",
      "Epoch 00109: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 174s 371us/sample - loss: 0.0313 - val_loss: 0.0688\n",
      "Epoch 110/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0300\n",
      "Epoch 00110: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 173s 367us/sample - loss: 0.0300 - val_loss: 0.0692\n",
      "Epoch 111/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0319\n",
      "Epoch 00111: val_loss did not improve from 0.06809\n",
      "470221/470221 [==============================] - 172s 367us/sample - loss: 0.0319 - val_loss: 0.0690\n",
      "Epoch 112/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0299\n",
      "Epoch 00112: val_loss improved from 0.06809 to 0.06783, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 176s 373us/sample - loss: 0.0299 - val_loss: 0.0678\n",
      "Epoch 113/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0300\n",
      "Epoch 00113: val_loss did not improve from 0.06783\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0300 - val_loss: 0.0696\n",
      "Epoch 114/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0308\n",
      "Epoch 00114: val_loss did not improve from 0.06783\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0308 - val_loss: 0.0710\n",
      "Epoch 115/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0306\n",
      "Epoch 00115: val_loss improved from 0.06783 to 0.06680, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0306 - val_loss: 0.0668\n",
      "Epoch 116/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0300\n",
      "Epoch 00116: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 172s 366us/sample - loss: 0.0300 - val_loss: 0.0695\n",
      "Epoch 117/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0303\n",
      "Epoch 00117: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0303 - val_loss: 0.0708\n",
      "Epoch 118/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0305\n",
      "Epoch 00118: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0305 - val_loss: 0.0701\n",
      "Epoch 119/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0299\n",
      "Epoch 00119: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0299 - val_loss: 0.0675\n",
      "Epoch 120/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0302\n",
      "Epoch 00120: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0302 - val_loss: 0.0669\n",
      "Epoch 121/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0301\n",
      "Epoch 00121: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0301 - val_loss: 0.0723\n",
      "Epoch 122/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0299\n",
      "Epoch 00122: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0299 - val_loss: 0.0676\n",
      "Epoch 123/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0291\n",
      "Epoch 00123: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 176s 375us/sample - loss: 0.0291 - val_loss: 0.0703\n",
      "Epoch 124/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0300\n",
      "Epoch 00124: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 176s 374us/sample - loss: 0.0300 - val_loss: 0.0690\n",
      "Epoch 125/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0291\n",
      "Epoch 00125: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 175s 373us/sample - loss: 0.0291 - val_loss: 0.0684\n",
      "Epoch 126/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0291\n",
      "Epoch 00126: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0291 - val_loss: 0.0696\n",
      "Epoch 127/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0312\n",
      "Epoch 00127: val_loss did not improve from 0.06680\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0312 - val_loss: 0.0715\n",
      "Epoch 128/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0283\n",
      "Epoch 00128: val_loss improved from 0.06680 to 0.06533, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 174s 371us/sample - loss: 0.0283 - val_loss: 0.0653\n",
      "Epoch 129/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0285\n",
      "Epoch 00129: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 172s 366us/sample - loss: 0.0285 - val_loss: 0.0718\n",
      "Epoch 130/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0301\n",
      "Epoch 00130: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 172s 366us/sample - loss: 0.0301 - val_loss: 0.0678\n",
      "Epoch 131/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0292\n",
      "Epoch 00131: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 175s 372us/sample - loss: 0.0292 - val_loss: 0.0669\n",
      "Epoch 132/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0291\n",
      "Epoch 00132: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0291 - val_loss: 0.0671\n",
      "Epoch 133/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0278\n",
      "Epoch 00133: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 173s 367us/sample - loss: 0.0278 - val_loss: 0.0692\n",
      "Epoch 134/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0294\n",
      "Epoch 00134: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 172s 367us/sample - loss: 0.0294 - val_loss: 0.0703\n",
      "Epoch 135/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0293\n",
      "Epoch 00135: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 172s 366us/sample - loss: 0.0293 - val_loss: 0.0687\n",
      "Epoch 136/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0282\n",
      "Epoch 00136: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 173s 367us/sample - loss: 0.0282 - val_loss: 0.0669\n",
      "Epoch 137/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0286\n",
      "Epoch 00137: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0286 - val_loss: 0.0680\n",
      "Epoch 138/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0282\n",
      "Epoch 00138: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0282 - val_loss: 0.0699\n",
      "Epoch 139/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0290\n",
      "Epoch 00139: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0290 - val_loss: 0.0659\n",
      "Epoch 140/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0276\n",
      "Epoch 00140: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0276 - val_loss: 0.0693\n",
      "Epoch 141/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0295\n",
      "Epoch 00141: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0295 - val_loss: 0.0670\n",
      "Epoch 142/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0270\n",
      "Epoch 00142: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0270 - val_loss: 0.0664\n",
      "Epoch 143/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0287\n",
      "Epoch 00143: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0287 - val_loss: 0.0691\n",
      "Epoch 144/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0278\n",
      "Epoch 00144: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0278 - val_loss: 0.0684\n",
      "Epoch 145/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0300\n",
      "Epoch 00145: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 370us/sample - loss: 0.0300 - val_loss: 0.0674\n",
      "Epoch 146/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0269\n",
      "Epoch 00146: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0269 - val_loss: 0.0662\n",
      "Epoch 147/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0274\n",
      "Epoch 00147: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0274 - val_loss: 0.0701\n",
      "Epoch 148/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0289\n",
      "Epoch 00148: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 174s 369us/sample - loss: 0.0289 - val_loss: 0.0676\n",
      "Epoch 149/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0277\n",
      "Epoch 00149: val_loss did not improve from 0.06533\n",
      "470221/470221 [==============================] - 173s 369us/sample - loss: 0.0277 - val_loss: 0.0719\n",
      "Epoch 150/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0281\n",
      "Epoch 00150: val_loss improved from 0.06533 to 0.06463, saving model to /workspace/data/checkpoints/EN-TF1-Full-20200408-194433\n",
      "470221/470221 [==============================] - 175s 371us/sample - loss: 0.0281 - val_loss: 0.0646\n",
      "Epoch 151/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0269\n",
      "Epoch 00151: val_loss did not improve from 0.06463\n",
      "470221/470221 [==============================] - 172s 366us/sample - loss: 0.0269 - val_loss: 0.0710\n",
      "Epoch 152/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0290\n",
      "Epoch 00152: val_loss did not improve from 0.06463\n",
      "470221/470221 [==============================] - 172s 365us/sample - loss: 0.0290 - val_loss: 0.0671\n",
      "Epoch 153/200\n",
      "470016/470221 [============================>.] - ETA: 0s - loss: 0.0280\n",
      "Epoch 00153: val_loss did not improve from 0.06463\n",
      "470221/470221 [==============================] - 173s 368us/sample - loss: 0.0280 - val_loss: 0.0664\n",
      "Epoch 154/200\n",
      " 82944/470221 [====>.........................] - ETA: 2:04 - loss: 0.0266"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4925b37a6c1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m          right[train_size:dataset_size]], \n\u001b[1;32m     12\u001b[0m         labels[train_size:dataset_size]),\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoints_callback\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#, tensorboard_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m ) \n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH = 512\n",
    "EPOCHS = 200\n",
    "\n",
    "history = model.fit(\n",
    "   [left[0:train_size], right[0:train_size]], \n",
    "    labels[0:train_size], \n",
    "    batch_size = BATCH, \n",
    "    epochs = EPOCHS,\n",
    "    validation_data = (\n",
    "        [left[train_size:dataset_size],\n",
    "         right[train_size:dataset_size]], \n",
    "        labels[train_size:dataset_size]),\n",
    "    callbacks=[checkpoints_callback] #, tensorboard_callback\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Vo50GX6luqq",
    "outputId": "fc38880b-de5e-4310-8a84-dac0221d03c5"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCj7kbzJluqw",
    "outputId": "636cb0ed-8f82-4983-a9df-59522aa868dc"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoint_path + '-history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6ZBogbfluq2"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lrAmY7_0luq3"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(labels, predicted_scores, threshold=0.5):\n",
    "    predicted = predicted_scores > threshold\n",
    "    predicted = predicted.astype(int).ravel()\n",
    "    return np.round(100*accuracy_score(labels, predicted), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgXbVJwNluq5"
   },
   "outputs": [],
   "source": [
    "def plot_roc_auc(actual, predictions):\n",
    "    fpr, tpr, roc_thresholds = roc_curve(actual, predictions)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='AUC  = {:.3f}'.format(auc_value))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "titSvg6-luq_"
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(actual, predictions):\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(actual, predictions)\n",
    "    avg_precision = average_precision_score(actual, predictions)\n",
    "    plt.plot(recall, precision, label='Avg Precision  = {:.3f}'.format(avg_precision))\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/csanc/checkpoints/EN-TF1-Full-20200408-194433/EN-TF1-Full-20200408-194433'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fbjg-Bl2lurC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fafa6d55438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_siamese_model()\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNc4F0kUlurG"
   },
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_val = left[train_size:dataset_size]\n",
    "right_val = right[train_size:dataset_size]\n",
    "labels_val = labels[train_size:dataset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14wW6FdBlurH"
   },
   "outputs": [],
   "source": [
    "predicted_val = model.predict([left_val, right_val]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZbrMx3-lurP",
    "outputId": "527ffb5c-402a-4204-adf2-2aac938a0a76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.72\n"
     ]
    }
   ],
   "source": [
    "#accuracy is a misleading metric here, we should look for the precision-recall\n",
    "#plot and select a threshold that priviledges precision but does not cause a \n",
    "#too low recall\n",
    "print('accuracy:', get_accuracy(labels_val, predicted_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Szz7Rtphlurb",
    "outputId": "133f23bd-9ec4-4406-bda6-ba29e39e99e2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(labels_val, predicted_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfFAbYD0lurd",
    "outputId": "2c274f07-91e9-42ba-f390-bc9b3a42f2e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall(labels_val, predicted_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeEbwXFGlurf"
   },
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulIHP593lurf",
    "outputId": "1ed56fcc-8e0b-4dd8-ceb1-43cbe8a7f4fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xander_English_2.mp3',\n",
       " 'Rose_Portuguese_3.m4a',\n",
       " 'Other_Spanish_4.mp3',\n",
       " 'Xander_English_5.m4a',\n",
       " 'Xander_English_3.mp3',\n",
       " 'Other_Spanish_5.mp3',\n",
       " 'Xander_English_4.mp3',\n",
       " 'Carlos_English_1.m4a',\n",
       " 'Rose_Portuguese_1.m4a',\n",
       " 'Other_Spanish_2.mp3',\n",
       " 'Carlos_English_2.m4a',\n",
       " 'Xander_English_1.mp3',\n",
       " 'Other_Spanish_3.mp3',\n",
       " 'Carlos_Portuguese_2.m4a',\n",
       " 'Rose_Portuguese_2.m4a',\n",
       " 'Rose_Portuguese_4.m4a',\n",
       " 'Carlos_Portuguese_1.m4a',\n",
       " 'Carlos_Portuguese_3.m4a',\n",
       " 'Xander_English_6.m4a',\n",
       " 'Other_Spanish_1.mp3',\n",
       " 'Carlos_English_3.m4a',\n",
       " 'Rose_Portuguese_5.m4a']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames = os.listdir(TEST_CLIPS)\n",
    "test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8sFv5Vc0lurg",
    "outputId": "c1f60016-812a-47ca-f84f-337e07930ac0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xander_English_2.mp3', 'Rose_Portuguese_3.m4a', 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs = []\n",
    "for a, b in itertools.combinations(test_filenames, 2):\n",
    "    test_pairs.append([a, b, int(a[0:a.find('_')] == b[0:b.find('_')])])\n",
    "test_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p5mmU1Bgluri"
   },
   "outputs": [],
   "source": [
    "def get_test_dataset():\n",
    "    left = []\n",
    "    right = []\n",
    "    labels = [] \n",
    "\n",
    "    test_clips = {}\n",
    "    for r in os.listdir(TEST_CLIPS):  \n",
    "        test_path = TEST_CLIPS + r\n",
    "        test_clips.update({r: get_clip(test_path)})\n",
    "\n",
    "   \n",
    "    for pair in test_pairs:       \n",
    "        left.append([test_clips.get(pair[0])]) \n",
    "        right.append([test_clips.get(pair[1])])\n",
    "        labels.append(np.float32(pair[2]))        \n",
    "    \n",
    "    left = np.array(left, dtype=np.float32)\n",
    "    right = np.array(right, dtype=np.float32)\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "    left = np.rollaxis(np.rollaxis(left, 3, 1), 3, 1)\n",
    "    right = np.rollaxis(np.rollaxis(right, 3, 1), 3, 1)\n",
    "\n",
    "    return left, right, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD7PTPFBlurl",
    "outputId": "a1d5e406-58dc-466a-b567-b591e6dc25c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((231, 20, 400, 1), (231, 20, 400, 1), (231,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_left, test_right, labels_test = get_test_dataset()\n",
    "test_left.shape, test_right.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AAK2mnCzluro"
   },
   "outputs": [],
   "source": [
    "predicted_test = model.predict([test_left, test_right]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HI1ZoWEflurq",
    "outputId": "1c566d98-f0b1-4371-c9f5-df8bdeb82154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.48\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', get_accuracy(labels_test, predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgw_ps28lurr",
    "outputId": "fceedd05-c584-49eb-f1a5-def474aff621"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(labels_test, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sdcei79mlurs",
    "outputId": "b6d7ea58-3ac4-4ff3-e548-a06cc935e697"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall(labels_test, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49wQxPi0lurw",
    "outputId": "792a20b4-61e8-401b-f4d1-7f96ecef5237"
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_pairs, columns=['voice_a', 'voice_b', 'label'])\n",
    "test_df['scores'] = predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h51knnb4lury",
    "outputId": "04080d16-a797-46f2-9ef3-679014a9a194"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voice_a</th>\n",
       "      <th>voice_b</th>\n",
       "      <th>label</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Other_Spanish_4.mp3</td>\n",
       "      <td>Rose_Portuguese_4.m4a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Other_Spanish_4.mp3</td>\n",
       "      <td>Rose_Portuguese_5.m4a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Xander_English_4.mp3</td>\n",
       "      <td>Carlos_English_1.m4a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Carlos_English_2.m4a</td>\n",
       "      <td>Rose_Portuguese_4.m4a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.896482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Carlos_English_2.m4a</td>\n",
       "      <td>Rose_Portuguese_5.m4a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  voice_a                voice_b  label    scores\n",
       "53    Other_Spanish_4.mp3  Rose_Portuguese_4.m4a      0  0.778900\n",
       "59    Other_Spanish_4.mp3  Rose_Portuguese_5.m4a      0  0.846316\n",
       "111  Xander_English_4.mp3   Carlos_English_1.m4a      0  0.515904\n",
       "169  Carlos_English_2.m4a  Rose_Portuguese_4.m4a      0  0.896482\n",
       "175  Carlos_English_2.m4a  Rose_Portuguese_5.m4a      0  0.939520"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives = (test_df['scores'] > 0.5) & (test_df['label'] == 0)\n",
    "test_df[false_positives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AJsvqbjlurz",
    "outputId": "8a0fb27c-9679-4756-e5b9-69be63a1418c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voice_a</th>\n",
       "      <th>voice_b</th>\n",
       "      <th>label</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xander_English_2.mp3</td>\n",
       "      <td>Xander_English_3.mp3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.185193e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xander_English_2.mp3</td>\n",
       "      <td>Xander_English_4.mp3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.469643e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Other_Spanish_4.mp3</td>\n",
       "      <td>Other_Spanish_1.mp3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.249869e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Xander_English_5.m4a</td>\n",
       "      <td>Xander_English_3.mp3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.013649e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Xander_English_3.mp3</td>\n",
       "      <td>Xander_English_4.mp3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.506980e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Xander_English_3.mp3</td>\n",
       "      <td>Xander_English_1.mp3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.832545e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Xander_English_3.mp3</td>\n",
       "      <td>Xander_English_6.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>1.592522e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Xander_English_4.mp3</td>\n",
       "      <td>Xander_English_6.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>4.836867e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Carlos_English_1.m4a</td>\n",
       "      <td>Carlos_Portuguese_2.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>3.684495e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Carlos_English_1.m4a</td>\n",
       "      <td>Carlos_Portuguese_1.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>1.722574e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Carlos_English_1.m4a</td>\n",
       "      <td>Carlos_English_3.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>3.191233e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Rose_Portuguese_1.m4a</td>\n",
       "      <td>Rose_Portuguese_2.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>2.951324e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Carlos_English_2.m4a</td>\n",
       "      <td>Carlos_Portuguese_1.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>2.438581e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Carlos_English_2.m4a</td>\n",
       "      <td>Carlos_English_3.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>1.387423e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Carlos_Portuguese_2.m4a</td>\n",
       "      <td>Carlos_Portuguese_3.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>7.748604e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Carlos_Portuguese_1.m4a</td>\n",
       "      <td>Carlos_Portuguese_3.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>9.030104e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Carlos_Portuguese_3.m4a</td>\n",
       "      <td>Carlos_English_3.m4a</td>\n",
       "      <td>1</td>\n",
       "      <td>4.768372e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     voice_a                  voice_b  label        scores\n",
       "3       Xander_English_2.mp3     Xander_English_3.mp3      1  1.185193e-01\n",
       "5       Xander_English_2.mp3     Xander_English_4.mp3      1  3.469643e-01\n",
       "57       Other_Spanish_4.mp3      Other_Spanish_1.mp3      1  3.249869e-01\n",
       "60      Xander_English_5.m4a     Xander_English_3.mp3      1  4.013649e-02\n",
       "79      Xander_English_3.mp3     Xander_English_4.mp3      1  4.506980e-01\n",
       "84      Xander_English_3.mp3     Xander_English_1.mp3      1  4.832545e-02\n",
       "91      Xander_English_3.mp3     Xander_English_6.m4a      1  1.592522e-01\n",
       "122     Xander_English_4.mp3     Xander_English_6.m4a      1  4.836867e-01\n",
       "131     Carlos_English_1.m4a  Carlos_Portuguese_2.m4a      1  3.684495e-01\n",
       "134     Carlos_English_1.m4a  Carlos_Portuguese_1.m4a      1  1.722574e-05\n",
       "138     Carlos_English_1.m4a     Carlos_English_3.m4a      1  3.191233e-04\n",
       "145    Rose_Portuguese_1.m4a    Rose_Portuguese_2.m4a      1  2.951324e-04\n",
       "170     Carlos_English_2.m4a  Carlos_Portuguese_1.m4a      1  2.438581e-02\n",
       "174     Carlos_English_2.m4a     Carlos_English_3.m4a      1  1.387423e-02\n",
       "198  Carlos_Portuguese_2.m4a  Carlos_Portuguese_3.m4a      1  7.748604e-07\n",
       "216  Carlos_Portuguese_1.m4a  Carlos_Portuguese_3.m4a      1  9.030104e-06\n",
       "223  Carlos_Portuguese_3.m4a     Carlos_English_3.m4a      1  4.768372e-07"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives = (test_df['scores'] < 0.5) & (test_df['label'] == 1)\n",
    "test_df[false_negatives]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "OneShot_Speech_Carlos_EN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
